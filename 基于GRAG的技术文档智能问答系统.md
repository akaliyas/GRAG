# 基于知识图谱增强检索生成的技术文档智能问答系统

**项目负责人：董志超**
---

## 项目概述

### 1.1 项目背景

随着技术文档的快速增长，传统的文档检索方式已无法满足开发者快速获取准确信息的需求。本项目旨在构建一个基于知识图谱增强检索生成（GraphRAG）的智能问答系统，通过结合向量检索和图结构检索，实现对技术文档的深度理解和精准问答。

### 1.2 项目目标

- **主要目标**：构建一个支持技术文档智能问答的系统，能够准确理解用户问题并基于文档内容生成高质量答案
- **技术目标**：展示GraphRAG技术在文档问答中的应用，包括知识图谱构建、双层检索机制、智能问答生成等核心技术
- **应用目标**：支持OpenAI官方文档等技术文档的智能问答，帮助开发者快速获取准确的技术指导

### 1.3 项目范围

- **数据来源**：OpenAI官方文档网站（https://platform.openai.com/docs）和Deepseek API docs（https://api-docs.deepseek.com/zh-cn/），以及可能的github项目文档。
- **数据规模**：单个来源约200-400页文档，总数据量约200-500MB
- **应用场景**：目前以单文档查询为主，支持开发者针对技术文档的智能问答，GRAG技术以支持将来多文档联查。

## 系统架构

### 2.1 整体架构

系统采用分层架构设计，包含以下核心层次：

```
┌─────────────────────────────────────────┐
│        应用层 (Application Layer)        │
│    FastAPI (后端) + Streamlit (前端)     │
└─────────────────────────────────────────┘
                    ↓
┌─────────────────────────────────────────┐
│         Agent层 (Agent Layer)           │
│         LangGraph (可选)                 │
└─────────────────────────────────────────┘
                    ↓
┌─────────────────────────────────────────┐
│         模型层 (Model Layer)             │
│   DeepSeek API / Llama-Factory LoRA     │
└─────────────────────────────────────────┘
                    ↓
┌─────────────────────────────────────────┐
│      知识存储层 (Knowledge Storage)       │
│    LightRAG (PostgreSQL/Neo4j后端)       │
└─────────────────────────────────────────┘
                    ↓
┌─────────────────────────────────────────┐
│      数据处理层 (Data Processing)         │
│         LightRAG (主要方案)               │
└─────────────────────────────────────────┘
                    ↓
┌─────────────────────────────────────────┐
│      数据采集层 (Data Collection)         │
│    Scrapy + Playwright (爬虫)            │
└─────────────────────────────────────────┘
```

### 2.2 核心流程

1. **数据采集**：使用Scrapy + Playwright爬取技术文档，处理JavaScript渲染页面
2. **数据处理**：通过LightRAG自动完成实体抽取、关系抽取、图构建和向量化
3. **知识存储**：将处理后的数据存储到PostgreSQL/Neo4j
4. **智能检索**：采用双层检索机制（全局检索+局部检索）获取相关上下文
5. **答案生成**：基于检索结果和知识图谱，使用LLM生成高质量答案

## 技术选型

### 3.1 核心技术栈

#### 3.1.1 数据处理层（优先采用LightRAG）

**主要方案：LightRAG**
- **选型理由**：
  - 成本优势：API调用次数减少约90%（3450-6900次 → 200-400次），成本从12-25元降至0.37-2.2元
  - 性能优势：双层检索机制，多数指标优于传统GraphRAG
  - 开发效率：使用现成框架，开发时间节省约50%
  - 增量更新：内置支持，符合每月更新需求

- **核心功能**：
  - 自动实体/关系抽取（批量处理，减少API调用）
  - 自动图构建和向量化
  - 双层检索（全局检索+局部检索）
  - 支持PostgreSQL和Neo4j作为存储后端

**备选方案：GraphRAG**
- 保留作为参考，适用于需要深度定制或处理复杂全局性问题的场景

#### 3.1.2 数据采集层

- **爬虫框架**：Scrapy + Playwright集成
  - Scrapy：处理结构化网站（如GitHub API）
  - Playwright：处理需要JavaScript渲染的文档网站，如openai官方文档
- **数据存储**：PostgreSQL（存储原始HTML和结构化数据）

#### 3.1.3 知识存储层

- **存储后端**：PostgreSQL（主要）或Neo4j（可选）
  - LightRAG统一管理所有存储（文档、实体、关系、图、向量）
  - PostgreSQL作为关联中心，同时承担API响应缓存功能
- **缓存策略**：PostgreSQL缓存表
  - 支持离线查询
  - 基于用户反馈的质量管理
  - LRU清理策略

#### 3.1.4 模型层（双方案支持）

**方案一：DeepSeek API（主要方案）**
- **适用场景**：快速开发、成本控制、资源受限
- **优势**：
  - 成本低：约0.37-2.2元总成本（200-400页文档）
  - 性能稳定：DeepSeek-V3性能优秀
  - 无需本地部署：简化架构，降低资源需求
- **集成方式**：LightRAG支持DeepSeek API，可配置自定义LLM函数

**方案二：Llama-Factory LoRA微调（扩展方案）**
- **适用场景**：需要离线能力、追求极致效果、有GPU资源
- **技术方案**：
  - 基础模型：Qwen7b、ChatGLM等开源模型
  - 微调方式：LoRA（参数高效微调）
  - 微调目标：针对技术文档问答任务进行领域适配
  - 部署方式：本地部署，通过Ollama或vLLM提供服务
- **切换策略**：支持API和本地模型的动态切换，根据资源情况和需求选择

#### 3.1.5 应用层

- **后端框架**：FastAPI
  - 异步支持，性能高
  - 自动生成API文档
  - 类型提示支持好
- **前端框架**：Streamlit
  - 开发速度快
  - 适合数据应用和演示

#### 3.1.6 部署方案

- **部署方式**：Docker Compose
- **服务配置**：
  - PostgreSQL：关系数据库和缓存
  - Neo4j：知识图谱（可选，如使用Neo4j后端）
  - FastAPI：后端API服务
  - Streamlit：前端Web界面
- **资源需求**：约1.2-1.6GB内存（适合16GB设备）

### 3.2 技术优势

1. **成本控制**：LightRAG方案大幅降低API调用成本（约90%节省）
2. **性能优化**：双层检索机制，检索效果优于传统RAG
3. **开发效率**：使用成熟框架，快速迭代
4. **灵活扩展**：支持API和本地模型双方案，适应不同场景
5. **增量更新**：内置支持，便于文档定期更新

## 核心功能

### 4.1 数据采集功能

- 支持JavaScript渲染页面的爬取（Playwright）
- 遵守robots.txt，控制爬取频率（1-2秒/请求）
- 数据清洗和结构化存储

### 4.2 知识图谱构建

- 自动实体抽取（框架、库、API、概念等）
- 自动关系抽取（依赖、导入、使用等）
- 知识图谱构建和存储

### 4.3 智能检索

- 双层检索机制：
  - 全局检索：识别主题簇，宏观理解
  - 局部检索：聚焦具体实体，精准定位
- 向量检索和图查询融合

### 4.4 智能问答

- 基于检索结果和知识图谱生成答案
- 支持上下文理解和多轮对话
- 答案质量评估和反馈机制

### 4.5 用户反馈

- 支持用户对答案质量的反馈
- 基于反馈优化缓存质量
- 持续改进系统性能

## 实施计划

### 5.1 开发阶段

**Phase 1：基础搭建（Week 1-2）**
- 环境配置（Docker Compose）
- 数据采集模块开发
- LightRAG集成和测试

**Phase 2：核心功能（Week 2-3）**
- 知识图谱构建
- 双层检索实现
- API服务开发

**Phase 3：应用开发（Week 3-4）**
- 前端界面开发
- 用户反馈功能
- 系统集成测试

**Phase 4：优化完善（Week 4）**
- 性能优化
- 准确度优化
- 文档编写

### 5.2 技术难点

1. **JavaScript渲染页面爬取**：使用Playwright处理SPA网站
2. **知识图谱构建**：确保实体和关系抽取的准确性
3. **双层检索融合**：优化全局检索和局部检索的结果融合
4. **模型切换**：实现API和本地模型的动态切换

### 5.3 风险评估

- **技术风险**：LightRAG框架的稳定性和兼容性（已评估，项目成熟度高）
- **数据风险**：爬取数据的合法性和质量（遵守robots.txt，控制频率）
- **成本风险**：API调用成本（已优化，成本可控）

## 预期成果

### 6.1 系统功能

- 完成技术文档智能问答系统的开发
- 支持OpenAI官方文档的智能问答
- 实现知识图谱增强的检索生成

### 6.2 技术指标

- **检索准确率**：Comprehensiveness 49.6-54.8%，Diversity 59.2-77.2%
- **响应时间**：平均响应时间 < 2秒
- **成本控制**：API调用成本 < 2.2元（200-400页文档）

### 6.3 学术价值

- 展示GraphRAG技术在文档问答中的应用
- 验证LightRAG和传统GraphRAG的性能差异
- 探索知识图谱增强检索的优化方法

## 技术特色

### 7.1 创新点

1. **双层检索机制**：结合全局检索和局部检索，提升检索效果
2. **成本优化**：通过LightRAG大幅降低API调用成本
3. **双模型方案**：支持API和本地模型，适应不同场景
4. **增量更新**：支持文档的增量更新，无需全量重建

### 7.2 技术深度

- 知识图谱构建和查询
- 向量检索和图检索融合
- LLM微调和Prompt工程
- 分布式系统设计（Docker部署）

## 总结

本项目旨在构建一个基于知识图谱增强检索生成的技术文档智能问答系统，通过采用LightRAG框架实现低成本、高性能的文档问答能力。系统支持DeepSeek API和Llama-Factory LoRA微调及部署双模型方案，能够适应不同的应用场景和资源条件。

