# 基于知识图谱增强检索生成的技术文档智能问答系统

---

## 项目概述

### 1.1 项目背景

随着技术文档的快速增长，传统的文档检索方式已无法满足开发者快速获取准确信息的需求。本项目旨在构建一个基于知识图谱增强检索生成（GraphRAG）的智能问答系统，通过结合向量检索和图结构检索，实现对技术文档的深度理解和精准问答。

### 1.2 项目目标

- **主要目标**：构建一个支持技术文档智能问答的系统，能够准确理解用户问题并基于文档内容生成高质量答案
- **技术目标**：展示GraphRAG技术在文档问答中的应用，包括知识图谱构建、双层检索机制、智能问答生成等核心技术
- **应用目标**：支持OpenAI官方文档等技术文档的智能问答，帮助开发者快速获取准确的技术指导

### 1.3 项目范围

- **数据来源**：OpenAI官方文档网站（https://platform.openai.com/docs）和Deepseek API docs（https://api-docs.deepseek.com/zh-cn/），以及可能的github项目文档。
- **数据规模**：单个来源约200-400页文档，总数据量约200-500MB
- **应用场景**：目前以单文档查询为主，支持开发者针对技术文档的智能问答，GRAG技术以支持将来多文档联查。

## 系统架构

### 2.1 整体架构

系统采用分层架构设计，包含以下核心层次：

```
┌─────────────────────────────────────────┐
│        应用层 (Application Layer)        │
│    FastAPI (后端) + Streamlit (前端)     │
└─────────────────────────────────────────┘
                    ↓
┌─────────────────────────────────────────┐
│         Agent层 (Agent Layer)           │
│         LangGraph (可选)                 │
└─────────────────────────────────────────┘
                    ↓
┌─────────────────────────────────────────┐
│         模型层 (Model Layer)             │
│   DeepSeek API / Llama-Factory LoRA     │
└─────────────────────────────────────────┘
                    ↓
┌─────────────────────────────────────────┐
│      知识存储层 (Knowledge Storage)       │
│    LightRAG (PostgreSQL/Neo4j后端)       │
└─────────────────────────────────────────┘
                    ↓
┌─────────────────────────────────────────┐
│      数据处理层 (Data Processing)         │
│         LightRAG (主要方案)               │
└─────────────────────────────────────────┘
                    ↓
┌─────────────────────────────────────────┐
│      数据采集层 (Data Collection)         │
│    Scrapy + Playwright (爬虫)            │
└─────────────────────────────────────────┘
```

### 2.2 核心流程

1. **数据采集**：使用Scrapy + Playwright爬取技术文档，处理JavaScript渲染页面
2. **数据处理**：通过LightRAG自动完成实体抽取、关系抽取、图构建和向量化
3. **知识存储**：将处理后的数据存储到PostgreSQL/Neo4j
4. **智能检索**：采用双层检索机制（全局检索+局部检索）获取相关上下文
5. **答案生成**：基于检索结果和知识图谱，使用LLM生成高质量答案

## 技术选型

### 3.1 核心技术栈

#### 3.1.1 数据处理层（优先采用LightRAG）

**主要方案：LightRAG**
- **选型理由**：
  - 成本优势：API调用次数减少约90%（3450-6900次 → 200-400次），成本从12-25元降至0.37-2.2元
  - 性能优势：双层检索机制，多数指标优于传统GraphRAG
  - 开发效率：使用现成框架，开发时间节省约50%
  - 增量更新：内置支持，符合每月更新需求

- **核心功能**：
  - 自动实体/关系抽取（批量处理，减少API调用）
  - 自动图构建和向量化
  - 双层检索（全局检索+局部检索）
  - 支持PostgreSQL和Neo4j作为存储后端

**备选方案：GraphRAG**
- 保留作为参考，适用于需要深度定制或处理复杂全局性问题的场景

#### 3.1.2 数据采集层

**主要方案：SaaS 爬虫服务（Firecrawl / Jina Reader）**

- **选型理由**：
  - **风险转移**：避免 IP 被封禁的风险，将反爬虫对抗交给专业服务商
  - **成本效益**：免费额度充足（Firecrawl 1000次/月，Jina 1000次/月），满足 200-400 页文档需求
  - **技术优势**：专业 IP 池、指纹对抗、自动处理验证码，成功率远高于自研方案
  - **开发效率**：无需维护反爬虫代码，专注于核心 RAG 功能开发
  - **合规性**：使用官方 API，避免违反服务条款

- **技术方案**：
  - **Firecrawl API**：支持 JavaScript 渲染，返回 Markdown/HTML 格式
  - **Jina Reader API**：专注于文档提取，返回结构化 Markdown
  - **MCP 集成**：支持通过 Model Context Protocol 集成，便于 Agent 调用

**备选方案：自研爬虫（仅用于测试/特殊场景）**

- **Scrapy + Playwright**：保留作为备选，用于：
  - 本地测试和开发
  - 处理不需要反爬虫的文档源（如 GitHub Markdown）
  - 特殊场景下的自定义需求
- **风险说明**：自研爬虫面临 IP 封禁、指纹对抗等风险，不适合生产环境

#### 3.1.3 知识存储层

- **存储后端**：PostgreSQL（主要）或Neo4j（可选）
  - LightRAG统一管理所有存储（文档、实体、关系、图、向量）
  - PostgreSQL作为关联中心，同时承担API响应缓存功能
- **缓存策略**：PostgreSQL缓存表
  - 支持离线查询
  - 基于用户反馈的质量管理
  - LRU清理策略

#### 3.1.4 模型层（双方案支持）

**方案一：DeepSeek API（主要方案）**
- **适用场景**：快速开发、成本控制、资源受限
- **优势**：
  - 成本低：约0.37-2.2元总成本（200-400页文档）
  - 性能稳定：DeepSeek-V3性能优秀
  - 无需本地部署：简化架构，降低资源需求
- **集成方式**：LightRAG支持DeepSeek API，可配置自定义LLM函数

**方案二：Llama-Factory LoRA微调（扩展方案）**
- **适用场景**：需要离线能力、追求极致效果、有GPU资源
- **技术方案**：
  - 基础模型：Qwen7b、ChatGLM等开源模型
  - 微调方式：LoRA（参数高效微调）
  - 微调目标：针对技术文档问答任务进行领域适配
  - 部署方式：本地部署，通过Ollama或vLLM提供服务
- **切换策略**：支持API和本地模型的动态切换，根据资源情况和需求选择

#### 3.1.5 应用层

- **后端框架**：FastAPI
  - 异步支持，性能高
  - 自动生成API文档
  - 类型提示支持好
- **前端框架**：Streamlit
  - 开发速度快
  - 适合数据应用和演示

#### 3.1.6 部署方案

- **部署方式**：Docker Compose
- **服务配置**：
  - PostgreSQL：关系数据库和缓存
  - Neo4j：知识图谱（可选，如使用Neo4j后端）
  - FastAPI：后端API服务
  - Streamlit：前端Web界面
- **资源需求**：约1.2-1.6GB内存（适合16GB设备）

### 3.2 技术优势

1. **成本控制**：LightRAG方案大幅降低API调用成本（约90%节省）
2. **性能优化**：双层检索机制，检索效果优于传统RAG
3. **开发效率**：使用成熟框架，快速迭代
4. **灵活扩展**：支持API和本地模型双方案，适应不同场景
5. **增量更新**：内置支持，便于文档定期更新

## 核心功能

### 4.1 数据采集功能

- **SaaS 服务集成**：通过 Firecrawl/Jina Reader API 获取文档内容
  - 自动处理 JavaScript 渲染（SPA 页面）
  - 自动处理反爬虫检测（Cloudflare 等）
  - 返回结构化 Markdown/HTML 格式
- **多源支持**：支持多种文档来源
  - 官方文档网站（通过 SaaS 服务）
  - GitHub 仓库（Markdown 文件，可直接读取）
  - 本地文件（手动保存的 HTML/Markdown）
- **数据清洗**：提取纯文本内容，去除无关元素
- **结构化存储**：将处理后的数据存储到 PostgreSQL

### 4.2 知识图谱构建

- 自动实体抽取（框架、库、API、概念等）
- 自动关系抽取（依赖、导入、使用等）
- 知识图谱构建和存储

### 4.3 智能检索

- 双层检索机制：
  - 全局检索：识别主题簇，宏观理解
  - 局部检索：聚焦具体实体，精准定位
- 向量检索和图查询融合

### 4.4 智能问答

- 基于检索结果和知识图谱生成答案
- 支持上下文理解和多轮对话
- 答案质量评估和反馈机制

### 4.5 用户反馈

- 支持用户对答案质量的反馈
- 基于反馈优化缓存质量
- 持续改进系统性能

## 实施计划

### 5.1 开发阶段

**Phase 1：基础搭建（Week 1-2）**
- 环境配置（Docker Compose）
- SaaS 爬虫服务集成（Firecrawl/Jina Reader）
- LightRAG 集成和测试
- 样本数据提取和验证

**Phase 2：核心功能（Week 2-3）**
- 知识图谱构建
- 双层检索实现
- API服务开发

**Phase 3：应用开发（Week 3-4）**
- 前端界面开发
- 用户反馈功能
- 系统集成测试

**Phase 4：优化完善（Week 4）**
- 性能优化
- 准确度优化
- 文档编写

### 5.2 技术难点

1. **数据采集策略**：选择合适的 SaaS 服务，平衡成本和可靠性
2. **知识图谱构建**：确保实体和关系抽取的准确性，优化 prompt 设计
3. **双层检索融合**：优化全局检索和局部检索的结果融合策略
4. **模型切换**：实现 API 和本地模型的动态切换，处理降级策略
5. **增量更新**：实现文档的增量更新机制，避免全量重建

### 5.3 风险评估

- **技术风险**：
  - LightRAG 框架的稳定性和兼容性（已评估，项目成熟度高）
  - SaaS 服务的可用性和稳定性（通过多服务商备选降低风险）
- **数据风险**：
  - 数据采集的合法性：使用 SaaS 服务确保合规性
  - 数据质量：通过清洗和验证确保内容准确性
- **成本风险**：
  - API 调用成本（LightRAG 已优化，成本可控）
  - SaaS 服务成本（免费额度充足，超出后按需付费）
- **运营风险**：
  - SaaS 服务商变更政策（通过多服务商降低依赖）
  - IP 封禁风险（已通过 SaaS 服务规避）

## 预期成果

### 6.1 系统功能

- 完成技术文档智能问答系统的开发
- 支持OpenAI官方文档的智能问答
- 实现知识图谱增强的检索生成

### 6.2 技术指标

- **检索准确率**：Comprehensiveness 49.6-54.8%，Diversity 59.2-77.2%
- **响应时间**：平均响应时间 < 2秒
- **成本控制**：API调用成本 < 2.2元（200-400页文档）

### 6.3 学术价值

- 展示GraphRAG技术在文档问答中的应用
- 验证LightRAG和传统GraphRAG的性能差异
- 探索知识图谱增强检索的优化方法

## 技术特色

### 7.1 创新点

1. **双层检索机制**：结合全局检索和局部检索，提升检索效果
2. **成本优化**：通过LightRAG大幅降低API调用成本
3. **双模型方案**：支持API和本地模型，适应不同场景
4. **增量更新**：支持文档的增量更新，无需全量重建

### 7.2 技术深度

- 知识图谱构建和查询
- 向量检索和图检索融合
- LLM微调和Prompt工程
- 分布式系统设计（Docker部署）

## 长期规划

### 8.1 短期目标（1-3个月）

**Phase 1：核心功能实现**
- 完成 SaaS 爬虫服务集成（Firecrawl/Jina Reader）
- 实现 LightRAG 知识图谱构建
- 完成双层检索机制
- 开发基础问答功能

**Phase 2：系统优化**
- 优化实体/关系抽取 prompt
- 实现增量更新机制
- 完善缓存策略
- 性能优化和监控

### 8.2 中期目标（3-6个月）

**功能扩展**
- 支持多文档源联合查询
- 实现知识图谱可视化界面
- 添加文档编辑和管理功能
- 支持用户自定义文档源

**技术深化**
- 探索更优的检索融合策略
- 优化知识图谱构建质量
- 实现模型微调（如需要）
- 提升问答准确率

### 8.3 长期目标（6-12个月）

**产品化**
- 完善前端 UI/UX
- 实现多租户支持
- 添加权限管理和安全机制
- 提供 API 服务

**技术演进**
- 探索更先进的 GraphRAG 技术
- 支持多模态文档（图片、表格等）
- 实现自动文档更新和同步
- 构建文档质量评估体系

### 8.4 技术债务管理

**数据采集策略**
- 短期：使用 SaaS 服务，快速验证和开发
- 中期：评估成本，考虑自建或混合方案
- 长期：根据实际需求选择最优方案

**模型策略**
- 短期：优先使用 DeepSeek API，成本低、效果好
- 中期：评估本地模型需求，如需要则实现
- 长期：根据使用场景动态选择最优模型

## 总结

本项目旨在构建一个基于知识图谱增强检索生成的技术文档智能问答系统，通过采用 LightRAG 框架实现低成本、高性能的文档问答能力。系统采用 SaaS 爬虫服务规避反爬虫风险，支持 DeepSeek API 和本地模型双方案，能够适应不同的应用场景和资源条件。

**核心设计理念**：
- **风险最小化**：使用专业 SaaS 服务处理反爬虫，避免 IP 封禁风险
- **成本优化**：通过 LightRAG 和合理的技术选型，控制整体成本
- **专注核心**：将开发精力集中在 RAG 和知识图谱等核心技术上
- **灵活扩展**：支持多种数据源和模型方案，便于未来扩展

