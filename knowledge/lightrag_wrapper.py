"""
LightRAG å°è£…æ¨¡å—
ç›´æ¥ä½¿ç”¨ LightRAG APIï¼Œæä¾›ç»Ÿä¸€çš„æ¥å£
"""
import json
import logging
import os
import sys
import asyncio
from pathlib import Path
from typing import List, Dict, Any, Optional
import numpy as np

logger = logging.getLogger(__name__)

# æ£€æµ‹æ˜¯å¦åœ¨ Jupyter ç¯å¢ƒä¸­
def _is_jupyter():
    """æ£€æµ‹æ˜¯å¦åœ¨ Jupyter Notebook æˆ– IPython ç¯å¢ƒä¸­"""
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰ IPython
        if 'IPython' in sys.modules:
            from IPython import get_ipython
            if get_ipython() is not None:
                return True
        # æ£€æŸ¥ç¯å¢ƒå˜é‡
        if 'ipykernel' in sys.modules:
            return True
        # æ£€æŸ¥æ˜¯å¦æœ‰è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯ï¼ˆJupyter é€šå¸¸æœ‰ï¼‰
        try:
            asyncio.get_running_loop()
            return True
        except RuntimeError:
            return False
    except:
        return False

# åœ¨ Jupyter ç¯å¢ƒä¸­å¯ç”¨åµŒå¥—äº‹ä»¶å¾ªç¯æ”¯æŒ
_jupyter_nest_asyncio_enabled = False
if _is_jupyter():
    try:
        import nest_asyncio
        nest_asyncio.apply()
        _jupyter_nest_asyncio_enabled = True
        logger.debug("å·²å¯ç”¨ nest_asyncio ä»¥æ”¯æŒ Jupyter Notebook")
    except ImportError:
        # nest_asyncio æœªå®‰è£…ï¼Œå°†ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
        logger.warning("nest_asyncio æœªå®‰è£…ï¼Œåœ¨ Jupyter ä¸­å¯èƒ½éœ€è¦å®‰è£…: pip install nest-asyncio")
        _jupyter_nest_asyncio_enabled = False

try:
    from lightrag import LightRAG, QueryParam
    from lightrag.utils import EmbeddingFunc
    # ================================================================
    # Ollama åµŒå…¥æ”¯æŒå·²å¼ƒç”¨
    # ================================================================
    # from lightrag.llm.ollama import ollama_embed
    from lightrag.llm.openai import openai_embed
except ImportError:
    LightRAG = None
    QueryParam = None
    EmbeddingFunc = None
    # ollama_embed = None  # å·²å¼ƒç”¨
    openai_embed = None

from config.config_manager import get_config
from models.model_manager import ModelManager
from utils.schema import CleanBatch, CleanDoc

logger = logging.getLogger(__name__)


class LightRAGWrapper:
    """LightRAG å°è£…ç±»"""
    
    def __init__(self, model_manager: ModelManager):
        """
        åˆå§‹åŒ– LightRAG å°è£…
        
        Args:
            model_manager: æ¨¡å‹ç®¡ç†å™¨å®ä¾‹
        """
        if LightRAG is None:
            raise ImportError("éœ€è¦å®‰è£… lightrag åº“: pip install lightrag")
        
        config = get_config()
        lightrag_config = config.get_lightrag_config()
        
        # è·å– LLM å‡½æ•°ï¼ˆé€‚é… LightRAGï¼‰
        self.model_manager = model_manager
        llm_func = self._create_llm_func()
        
        # åˆ›å»º Embedding å‡½æ•°
        embedding_func = self._create_embedding_func(lightrag_config, config)
        
        # è·å–å­˜å‚¨é…ç½®
        storage_type = lightrag_config.get('storage_type', 'postgresql')
        db_config = config.get_database_config()
        
        # è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆLightRAG é€šè¿‡ç¯å¢ƒå˜é‡è¯»å–æ•°æ®åº“é…ç½®ï¼‰
        if storage_type == 'postgresql':
            os.environ.setdefault('POSTGRES_HOST', str(db_config.get('host', 'localhost')))
            os.environ.setdefault('POSTGRES_PORT', str(db_config.get('port', 5432)))
            os.environ.setdefault('POSTGRES_USER', str(db_config.get('user', '')))
            os.environ.setdefault('POSTGRES_PASSWORD', str(db_config.get('password', '')))
            os.environ.setdefault('POSTGRES_DATABASE', str(db_config.get('database', 'grag_db')))
            os.environ.setdefault('POSTGRES_MAX_CONNECTIONS', str(db_config.get('pool_size', 10)))
            
            # è®¾ç½® PostgreSQL å­˜å‚¨ç±»å‹
            kv_storage = lightrag_config.get('kv_storage', 'PGKVStorage')
            vector_storage = lightrag_config.get('vector_storage', 'PGVectorStorage')
            graph_storage = lightrag_config.get('graph_storage', 'PGGraphStorage')
            doc_status_storage = lightrag_config.get('doc_status_storage', 'PGDocStatusStorage')
        else:
            # é»˜è®¤ä½¿ç”¨æ–‡ä»¶å­˜å‚¨ï¼ˆJsonKVStorage, NetworkXStorage, NanoVectorDBStorageï¼‰
            kv_storage = lightrag_config.get('kv_storage', 'JsonKVStorage')
            vector_storage = lightrag_config.get('vector_storage', 'NanoVectorDBStorage')
            graph_storage = lightrag_config.get('graph_storage', 'NetworkXStorage')
            doc_status_storage = lightrag_config.get('doc_status_storage', 'JsonDocStatusStorage')
        
        # åˆå§‹åŒ– LightRAG
        self.rag = LightRAG(
            llm_model_func=llm_func,
            embedding_func=embedding_func,  # æ·»åŠ  embedding_func
            kv_storage=kv_storage,
            vector_storage=vector_storage,
            graph_storage=graph_storage,
            doc_status_storage=doc_status_storage,
            working_dir=lightrag_config.get('working_dir', './rag_storage'),
            workspace=lightrag_config.get('workspace', '')
        )
        
        # å¯¹äº PostgreSQL å­˜å‚¨ï¼Œéœ€è¦æ˜¾å¼åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
        if storage_type == 'postgresql':
            try:
                # åœ¨ Jupyter ç¯å¢ƒä¸­ï¼Œä½¿ç”¨ nest_asyncio æˆ–æ–°çº¿ç¨‹
                if _is_jupyter():
                    if _jupyter_nest_asyncio_enabled:
                        # nest_asyncio å·²å¯ç”¨ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨
                        loop = asyncio.get_event_loop()
                        loop.run_until_complete(self.rag.initialize_storages())
                    else:
                        # åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œå¼‚æ­¥åˆå§‹åŒ–
                        import concurrent.futures
                        with concurrent.futures.ThreadPoolExecutor() as executor:
                            future = executor.submit(
                                lambda: asyncio.run(self.rag.initialize_storages())
                            )
                            future.result()
                else:
                    # é Jupyter ç¯å¢ƒï¼Œç›´æ¥ä½¿ç”¨ asyncio.run
                    asyncio.run(self.rag.initialize_storages())
                logger.info("âœ… PostgreSQL æ•°æ®åº“è¿æ¥å·²åˆå§‹åŒ–")
            except Exception as e:
                error_msg = str(e)
                logger.error(f"âŒ PostgreSQL æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {error_msg}")
                if "connection" in error_msg.lower() or "connect" in error_msg.lower():
                    logger.error("ğŸ’¡ æç¤º: è¯·æ£€æŸ¥ PostgreSQL æœåŠ¡æ˜¯å¦è¿è¡Œï¼Œä»¥åŠæ•°æ®åº“é…ç½®æ˜¯å¦æ­£ç¡®")
                    logger.error(f"ğŸ’¡ æç¤º: æ£€æŸ¥æ•°æ®åº“è¿æ¥ - Host: {db_config.get('host')}, Port: {db_config.get('port')}, Database: {db_config.get('database')}")
                raise RuntimeError(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {error_msg}") from e
        
        logger.info(f"LightRAG å·²åˆå§‹åŒ–ï¼Œå­˜å‚¨ç±»å‹: {storage_type}")
        logger.info(f"  KVå­˜å‚¨: {kv_storage}, å‘é‡å­˜å‚¨: {vector_storage}, å›¾å­˜å‚¨: {graph_storage}")
        logger.info(f"  åµŒå…¥æ¨¡å‹: {lightrag_config.get('embedding_model', 'unknown')}, "
                   f"æä¾›å•†: {lightrag_config.get('embedding_provider', 'unknown')}")
    
    def _create_llm_func(self):
        """
        åˆ›å»º LLM å‡½æ•°ï¼Œé€‚é… LightRAG
        
        Returns:
            LLM å‡½æ•°
        """
        def llm_func(messages: List[Dict[str, str]], **kwargs) -> str:
            """
            LightRAG éœ€è¦çš„ LLM å‡½æ•°æ ¼å¼
            
            Args:
                messages: æ¶ˆæ¯åˆ—è¡¨
                **kwargs: å…¶ä»–å‚æ•°
                
            Returns:
                æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬
            """
            try:
                response = self.model_manager.chat_completion(
                    messages=messages,
                    temperature=kwargs.get('temperature', 0.7),
                    max_tokens=kwargs.get('max_tokens', 2000),
                    stream=False
                )
                
                # æå–å“åº”æ–‡æœ¬
                if hasattr(response, 'choices') and len(response.choices) > 0:
                    return response.choices[0].message.content
                else:
                    return str(response)
            except Exception as e:
                logger.error(f"LLM è°ƒç”¨å¤±è´¥: {e}")
                raise
        
        return llm_func
    
    def _create_embedding_func(self, lightrag_config: Dict[str, Any], config: Any):
        """
        åˆ›å»º Embedding å‡½æ•°ï¼Œé€‚é… LightRAG
        æ ¹æ®é…ç½®ä¸­çš„ embedding_provider è‡ªåŠ¨é€‰æ‹©ä½¿ç”¨ SiliconFlow æˆ– OpenAI API
        æ³¨æ„ï¼šOllama åµŒå…¥æ”¯æŒå·²å¼ƒç”¨
        
        Args:
            lightrag_config: LightRAG é…ç½®å­—å…¸
            config: é…ç½®ç®¡ç†å™¨å®ä¾‹
            
        Returns:
            EmbeddingFunc å¯¹è±¡
        """
        if EmbeddingFunc is None:
            raise ImportError("éœ€è¦å®‰è£… lightrag åº“: pip install lightrag")
        
        embedding_model = lightrag_config.get('embedding_model', 'BAAI/bge-m3')
        embedding_provider_raw = lightrag_config.get('embedding_provider', 'siliconflow')
        
        # å¦‚æœå€¼ä»ç„¶æ˜¯ç¯å¢ƒå˜é‡æ ¼å¼ï¼ˆæœªè§£æï¼‰ï¼Œæ‰‹åŠ¨è§£æ
        if isinstance(embedding_provider_raw, str) and embedding_provider_raw.startswith("${") and embedding_provider_raw.endswith("}"):
            var_expr = embedding_provider_raw[2:-1]
            if ":" in var_expr:
                var_name, default_value = var_expr.split(":", 1)
                embedding_provider = os.getenv(var_name.strip(), default_value.strip()).lower()
            else:
                embedding_provider = os.getenv(var_expr.strip(), 'siliconflow').lower()
        else:
            embedding_provider = embedding_provider_raw.lower() if embedding_provider_raw else 'siliconflow'
        
        # SiliconFlow æˆ– OpenAI å…¼å®¹ API
        if embedding_provider in ['siliconflow', 'openai']:
            if openai_embed is None:
                raise ImportError("éœ€è¦å®‰è£… lightrag åº“ä»¥ä½¿ç”¨ OpenAI å…¼å®¹çš„åµŒå…¥åŠŸèƒ½")
            
            # è·å– API key å’Œ base_url
            api_key = lightrag_config.get('embedding_api_key') or os.getenv('EMBEDDING_API_KEY')
            base_url = lightrag_config.get('embedding_base_url') or os.getenv('EMBEDDING_BASE_URL')
            
            # å¦‚æœæ²¡æœ‰é…ç½®ï¼Œå°è¯•ä»ç¯å¢ƒå˜é‡æˆ–é»˜è®¤å€¼è·å–
            if not api_key:
                # å°è¯•ä» OpenAI API key ç¯å¢ƒå˜é‡è·å–
                api_key = os.getenv('OPENAI_API_KEY')
            
            if not base_url:
                if embedding_provider == 'siliconflow':
                    base_url = 'https://api.siliconflow.cn/v1'
                else:
                    base_url = 'https://api.openai.com/v1'
            
            if not api_key:
                raise ValueError(
                    f"æœªæ‰¾åˆ° {embedding_provider} API keyã€‚"
                    f"è¯·è®¾ç½® EMBEDDING_API_KEY ç¯å¢ƒå˜é‡æˆ–åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½® embedding_api_keyã€‚"
                )
            
            # æ ¹æ®æ¨¡å‹ç¡®å®šåµŒå…¥ç»´åº¦
            # SiliconFlow æ”¯æŒçš„æ¨¡å‹ç»´åº¦ï¼š
            # - BAAI/bge-m3: 1024
            # - Pro/BAAI/bge-m3: 1024
            # - BAAI/bge-large-zh-v1.5: 1024
            # - BAAI/bge-large-en-v1.5: 1024
            # - Qwen/Qwen3-Embedding-8B: 8192
            # - Qwen/Qwen3-Embedding-4B: 4096
            # - Qwen/Qwen3-Embedding-0.6B: 512
            embedding_dim_map = {
                # SiliconFlow bge-m3 ç³»åˆ—
                'baai/bge-m3': 1024,
                'pro/baai/bge-m3': 1024,
                'baai/bge-large-zh-v1.5': 1024,
                'baai/bge-large-en-v1.5': 1024,
                # Qwen ç³»åˆ—
                'qwen/qwen3-embedding-8b': 8192,
                'qwen/qwen3-embedding-4b': 4096,
                'qwen/qwen3-embedding-0.6b': 512,
                # OpenAI ç³»åˆ—
                'text-embedding-3-small': 1536,
                'text-embedding-3-large': 3072,
                'text-embedding-ada-002': 1536,
            }
            
            # ä½¿ç”¨æ¨¡å‹åç§°çš„å°å†™å½¢å¼è¿›è¡ŒåŒ¹é…
            model_key = embedding_model.lower()
            embedding_dim = embedding_dim_map.get(model_key, 1024)  # é»˜è®¤ 1024
            
            # åˆ›å»º OpenAI å…¼å®¹çš„åµŒå…¥å‡½æ•°
            async def embedding_func(texts: List[str]) -> np.ndarray:
                """
                OpenAI å…¼å®¹çš„åµŒå…¥å‡½æ•°ï¼ˆæ”¯æŒ SiliconFlowï¼‰
                
                Args:
                    texts: æ–‡æœ¬åˆ—è¡¨
                    
                Returns:
                    åµŒå…¥å‘é‡ numpy æ•°ç»„
                """
                try:
                    return await openai_embed(
                        texts,
                        model=embedding_model,
                        api_key=api_key,
                        base_url=base_url,
                    )
                except Exception as e:
                    logger.error(f"{embedding_provider} Embedding è°ƒç”¨å¤±è´¥: {e}")
                    raise
            
            logger.info(f"ä½¿ç”¨ {embedding_provider} åµŒå…¥æ¨¡å‹: {embedding_model}, "
                       f"ç»´åº¦: {embedding_dim}, APIåœ°å€: {base_url}")
            
            return EmbeddingFunc(
                embedding_dim=embedding_dim,
                max_token_size=8192,  # å¤§å¤šæ•°æ¨¡å‹æ”¯æŒ 8192 tokens
                func=embedding_func
            )
        
        # ========================================================================
        # Ollama æœ¬åœ°æ¨¡å‹åµŒå…¥æ”¯æŒå·²å¼ƒç”¨
        # ========================================================================
        # elif embedding_provider == 'ollama':
        #     if ollama_embed is None:
        #         raise ImportError("éœ€è¦å®‰è£… lightrag åº“ä»¥ä½¿ç”¨ Ollama åµŒå…¥åŠŸèƒ½")
        #     
        #     # è·å– Ollama ä¸»æœºåœ°å€ï¼ˆä»é…ç½®æˆ–ç¯å¢ƒå˜é‡ï¼‰
        #     embedding_host = lightrag_config.get('embedding_base_url') or os.getenv(
        #         'EMBEDDING_BINDING_HOST',
        #         os.getenv('LOCAL_MODEL_URL', 'http://localhost:11434')
        #     )
        #     
        #     # Ollama æ¨¡å‹çš„åµŒå…¥ç»´åº¦æ˜ å°„
        #     embedding_dim_map = {
        #         'bge-m3': 1024,
        #         'bge-m3:latest': 1024,
        #         'nomic-embed-text': 768,
        #         'nomic-embed-text:latest': 768,
        #     }
        #     embedding_dim = embedding_dim_map.get(embedding_model.lower(), 1024)
        #     
        #     # åˆ›å»º Ollama åµŒå…¥å‡½æ•°
        #     async def embedding_func(texts: List[str]) -> np.ndarray:
        #         """
        #         Ollama åµŒå…¥å‡½æ•°
        #         
        #         Args:
        #             texts: æ–‡æœ¬åˆ—è¡¨
        #             
        #         Returns:
        #             åµŒå…¥å‘é‡ numpy æ•°ç»„
        #         """
        #         try:
        #             return await ollama_embed(
        #                 texts,
        #                 embed_model=embedding_model,
        #                 host=embedding_host,
        #             )
        #         except Exception as e:
        #             logger.error(f"Ollama Embedding è°ƒç”¨å¤±è´¥: {e}")
        #             raise
        #     
        #     logger.info(f"ä½¿ç”¨ Ollama åµŒå…¥æ¨¡å‹: {embedding_model}, "
        #                f"ç»´åº¦: {embedding_dim}, ä¸»æœº: {embedding_host}")
        #     
        #     return EmbeddingFunc(
        #         embedding_dim=embedding_dim,
        #         max_token_size=8192,
        #         func=embedding_func
        #     )
        
        elif embedding_provider == 'ollama':
            raise ValueError(
                "Ollama åµŒå…¥æ”¯æŒå·²å¼ƒç”¨ã€‚"
                "è¯·ä½¿ç”¨ siliconflow æˆ– openai ä½œä¸º embedding_providerã€‚"
            )
        
        else:
            raise ValueError(
                f"ä¸æ”¯æŒçš„åµŒå…¥æä¾›å•†: {embedding_provider}ã€‚"
                f"æ”¯æŒçš„é€‰é¡¹: siliconflow, openaiï¼ˆollama å·²å¼ƒç”¨ï¼‰"
            )
    
    def add_documents(
        self, 
        documents: List[str], 
        metadatas: Optional[List[Dict]] = None,
        file_paths: Optional[List[str]] = None
    ):
        """
        æ·»åŠ æ–‡æ¡£åˆ°çŸ¥è¯†åº“
        
        Args:
            documents: æ–‡æ¡£åˆ—è¡¨ï¼ˆæ–‡æœ¬å†…å®¹ï¼‰
            metadatas: å…ƒæ•°æ®åˆ—è¡¨ï¼ˆå¯é€‰ï¼Œå·²åºŸå¼ƒï¼Œä¿ç•™ä»¥å…¼å®¹æ—§ä»£ç ï¼‰
            file_paths: æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼ˆç”¨äºå¼•æ–‡åŠŸèƒ½ï¼‰
        """
        try:
            # ä½¿ç”¨ LightRAG çš„ insert æ–¹æ³•ï¼Œæ”¯æŒ file_paths å‚æ•°
            # å¦‚æœ nest_asyncio å·²å¯ç”¨ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ insert æ–¹æ³•
            if file_paths and len(file_paths) == len(documents):
                # æ‰¹é‡æ’å…¥ï¼Œå¸¦æ–‡ä»¶è·¯å¾„
                self.rag.insert(documents, file_paths=file_paths)
            else:
                # æ‰¹é‡æ’å…¥ï¼Œä¸å¸¦æ–‡ä»¶è·¯å¾„
                self.rag.insert(documents)
            
            logger.info(f"å·²æ·»åŠ  {len(documents)} ä¸ªæ–‡æ¡£åˆ°çŸ¥è¯†åº“")
        except RuntimeError as e:
            # å¦‚æœæ˜¯äº‹ä»¶å¾ªç¯é”™è¯¯ï¼Œå°è¯•ä½¿ç”¨å¼‚æ­¥æ–¹æ³•
            error_msg = str(e).lower()
            if "event loop" in error_msg or "already running" in error_msg:
                if _is_jupyter():
                    logger.warning("âš ï¸ æ£€æµ‹åˆ° Jupyter äº‹ä»¶å¾ªç¯å†²çªï¼Œå°è¯•ä½¿ç”¨å¼‚æ­¥æ–¹æ³•...")
                    logger.info("ğŸ’¡ æç¤º: å®‰è£… nest-asyncio å¯é¿å…æ­¤é—®é¢˜: pip install nest-asyncio")
                    try:
                        # åœ¨ Jupyter ä¸­ï¼Œå°è¯•ä½¿ç”¨ nest_asyncio æˆ–ç›´æ¥ä½¿ç”¨å¼‚æ­¥æ–¹æ³•
                        if _jupyter_nest_asyncio_enabled:
                            # nest_asyncio å·²å¯ç”¨ï¼Œé‡è¯• insert
                            if file_paths and len(file_paths) == len(documents):
                                self.rag.insert(documents, file_paths=file_paths)
                            else:
                                self.rag.insert(documents)
                        else:
                            # å°è¯•åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œ
                            import concurrent.futures
                            with concurrent.futures.ThreadPoolExecutor() as executor:
                                if file_paths and len(file_paths) == len(documents):
                                    future = executor.submit(
                                        lambda: asyncio.run(self.rag.ainsert(documents, file_paths=file_paths))
                                    )
                                else:
                                    future = executor.submit(
                                        lambda: asyncio.run(self.rag.ainsert(documents))
                                    )
                                future.result()
                        logger.info(f"âœ… å·²æ·»åŠ  {len(documents)} ä¸ªæ–‡æ¡£åˆ°çŸ¥è¯†åº“ï¼ˆä½¿ç”¨å¼‚æ­¥æ–¹æ³•ï¼‰")
                    except Exception as e2:
                        error_detail = str(e2)
                        logger.error(f"âŒ å¼‚æ­¥æ–¹æ³•ä¹Ÿå¤±è´¥: {error_detail}")
                        if "event loop" in error_detail.lower():
                            raise RuntimeError(
                                "äº‹ä»¶å¾ªç¯å†²çªã€‚è¯·åœ¨ Jupyter Notebook çš„ç¬¬ä¸€ä¸ª cell ä¸­è¿è¡Œ:\n"
                                "  !pip install nest-asyncio\n"
                                "  import nest_asyncio\n"
                                "  nest_asyncio.apply()"
                            ) from e2
                        raise RuntimeError(f"æ·»åŠ æ–‡æ¡£æ—¶å‘ç”Ÿé”™è¯¯: {error_detail}") from e2
                else:
                    raise RuntimeError(f"äº‹ä»¶å¾ªç¯é”™è¯¯: {e}") from e
            else:
                raise
        except Exception as e:
            error_msg = str(e)
            logger.error(f"âŒ æ·»åŠ æ–‡æ¡£å¤±è´¥: {error_msg}")
            # æä¾›æ›´å‹å¥½çš„é”™è¯¯ä¿¡æ¯
            if "api" in error_msg.lower() or "key" in error_msg.lower():
                logger.error("ğŸ’¡ æç¤º: è¯·æ£€æŸ¥ API é…ç½®å’Œå¯†é’¥æ˜¯å¦æ­£ç¡®è®¾ç½®")
            raise
    
    def ingest_batch(self, batch: CleanBatch) -> Dict[str, Any]:
        """
        æ ¸å¿ƒé€»è¾‘ï¼šæ¥æ”¶æ¸…æ´—åçš„æ‰¹æ¬¡å¹¶å¯¼å…¥åˆ° LightRAG
        
        å®ç° Insert + Update åŒæ­¥èµ°ç­–ç•¥ï¼š
        1. Insert: è°ƒç”¨ rag.insert() æ’å…¥æ–‡æ¡£ï¼ˆä½¿ç”¨è‡ªå®šä¹‰ doc_idï¼‰
        2. Update: æ‰‹åŠ¨æ‰§è¡Œ SQL æ›´æ–° metadata åˆ° LIGHTRAG_DOC_FULL.meta å­—æ®µ
        
        Args:
            batch: CleanBatch Pydantic å¯¹è±¡
            
        Returns:
            å¯¼å…¥ç»“æœç»Ÿè®¡ä¿¡æ¯
        """
        try:
            # æå–æ–‡æ¡£å†…å®¹ã€æ–‡ä»¶è·¯å¾„å’Œ doc_ids
            texts = []
            file_paths = []
            doc_ids = []
            metadata_list = []  # ç”¨äºåç»­ Update
            
            for doc in batch.docs:
                if not doc.content:
                    logger.warning(f"æ–‡æ¡£å†…å®¹ä¸ºç©ºï¼Œè·³è¿‡: {doc.file_path}")
                    continue
                
                texts.append(doc.content)
                file_paths.append(doc.file_path)
                doc_ids.append(doc.doc_id)
                metadata_list.append({
                    'doc_id': doc.doc_id,
                    'metadata': doc.metadata,
                    'source_url': doc.source_url,
                    'file_path': doc.file_path,
                    'file_type': doc.file_type
                })
            
            if not texts:
                logger.warning("æ²¡æœ‰æœ‰æ•ˆçš„æ–‡æ¡£å†…å®¹")
                return {
                    'success': False,
                    'message': 'æ²¡æœ‰æœ‰æ•ˆçš„æ–‡æ¡£å†…å®¹',
                    'total_documents': 0
                }
            
            # Step 1: Insert - è°ƒç”¨ LightRAG çš„ insert æ–¹æ³•ï¼ˆä¼ å…¥è‡ªå®šä¹‰ IDsï¼‰
            logger.info(f"å¼€å§‹æ’å…¥ {len(texts)} ä¸ªæ–‡æ¡£åˆ° LightRAG...")
            try:
                self.rag.insert(texts, ids=doc_ids, file_paths=file_paths)
            except RuntimeError as e:
                # å¦‚æœæ˜¯äº‹ä»¶å¾ªç¯é”™è¯¯ï¼Œå°è¯•ä½¿ç”¨å¼‚æ­¥æ–¹æ³•
                error_msg = str(e).lower()
                if "event loop" in error_msg or "already running" in error_msg:
                    if _is_jupyter():
                        logger.warning("âš ï¸ æ£€æµ‹åˆ° Jupyter äº‹ä»¶å¾ªç¯å†²çªï¼Œå°è¯•ä½¿ç”¨å¼‚æ­¥æ–¹æ³•...")
                        logger.info("ğŸ’¡ æç¤º: å®‰è£… nest-asyncio å¯é¿å…æ­¤é—®é¢˜: pip install nest-asyncio")
                        try:
                            # åœ¨ Jupyter ä¸­ï¼Œå°è¯•ä½¿ç”¨ nest_asyncio æˆ–ç›´æ¥ä½¿ç”¨å¼‚æ­¥æ–¹æ³•
                            if _jupyter_nest_asyncio_enabled:
                                # nest_asyncio å·²å¯ç”¨ï¼Œé‡è¯• insert
                                self.rag.insert(texts, ids=doc_ids, file_paths=file_paths)
                            else:
                                # å°è¯•åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œ
                                import concurrent.futures
                                with concurrent.futures.ThreadPoolExecutor() as executor:
                                    future = executor.submit(
                                        lambda: asyncio.run(self.rag.ainsert(texts, ids=doc_ids, file_paths=file_paths))
                                    )
                                    future.result()
                        except Exception as e2:
                            error_detail = str(e2)
                            logger.error(f"âŒ å¼‚æ­¥æ–¹æ³•ä¹Ÿå¤±è´¥: {error_detail}")
                            if "event loop" in error_detail.lower():
                                raise RuntimeError(
                                    "äº‹ä»¶å¾ªç¯å†²çªã€‚è¯·åœ¨ Jupyter Notebook çš„ç¬¬ä¸€ä¸ª cell ä¸­è¿è¡Œ:\n"
                                    "  !pip install nest-asyncio\n"
                                    "  import nest_asyncio\n"
                                    "  nest_asyncio.apply()\n"
                                    "ç„¶åé‡æ–°è¿è¡Œæ­¤ä»£ç ã€‚"
                                )
                            raise
                    else:
                        raise
                else:
                    raise
            
            logger.info(f"âœ… æˆåŠŸæ’å…¥ {len(texts)} ä¸ªæ–‡æ¡£åˆ° LightRAG")
            
            # Step 2: Update - æ‰‹åŠ¨æ›´æ–° Metadata åˆ° LIGHTRAG_DOC_FULL.meta å­—æ®µ
            logger.info("å¼€å§‹æ›´æ–° Metadata...")
            updated_count = self._update_metadata_batch(metadata_list)
            logger.info(f"âœ… æˆåŠŸæ›´æ–° {updated_count}/{len(metadata_list)} ä¸ªæ–‡æ¡£çš„ Metadata")
            
            return {
                'success': True,
                'total_documents': len(texts),
                'metadata_updated': updated_count,
                'source_url': batch.source_url,
                'cleaned_at': batch.cleaned_at.isoformat() if batch.cleaned_at else None
            }
            
        except Exception as e:
            logger.error(f"å¯¼å…¥æ‰¹æ¬¡å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return {
                'success': False,
                'error': str(e),
                'total_documents': 0
            }
    
    def _update_metadata_batch(self, metadata_list: List[Dict[str, Any]]) -> int:
        """
        æ‰¹é‡æ›´æ–° Metadata åˆ° LIGHTRAG_DOC_FULL.meta å­—æ®µ
        
        ä½¿ç”¨ LightRAG çš„ PostgreSQLDB è¿æ¥æ‰§è¡Œ SQL UPDATEã€‚
        
        Args:
            metadata_list: åŒ…å« doc_id å’Œ metadata çš„å­—å…¸åˆ—è¡¨
            
        Returns:
            æˆåŠŸæ›´æ–°çš„æ–‡æ¡£æ•°é‡
        """
        try:
            # è·å– LightRAG çš„ workspaceï¼ˆé»˜è®¤æ˜¯ "default"ï¼‰
            workspace = os.environ.get("POSTGRES_WORKSPACE", "default")
            
            # å°è¯•è·å– LightRAG çš„æ•°æ®åº“è¿æ¥
            # æ³¨æ„ï¼šLightRAG ä½¿ç”¨ ClientManager ç®¡ç†è¿æ¥ï¼Œæˆ‘ä»¬éœ€è¦é€šè¿‡å­˜å‚¨å±‚è®¿é—®
            from lightrag.kg.postgres_impl import ClientManager
            
            # ä½¿ç”¨å¼‚æ­¥æ–¹å¼æ›´æ–°ï¼ˆLightRAG çš„æ•°æ®åº“æ“ä½œéƒ½æ˜¯å¼‚æ­¥çš„ï¼‰
            async def update_metadata_async():
                db = await ClientManager.get_client()
                updated_count = 0
                
                for meta_info in metadata_list:
                    doc_id = meta_info['doc_id']
                    metadata_json = json.dumps(meta_info['metadata'], ensure_ascii=False)
                    
                    # æ‰§è¡Œ UPDATE SQL
                    # æ³¨æ„ï¼šPostgreSQLDB.execute() ä½¿ç”¨å­—å…¸ï¼Œç„¶åè½¬æ¢ä¸º tuple(data.values())
                    # SQL éœ€è¦ä½¿ç”¨ $1, $2, $3 å ä½ç¬¦ï¼ˆasyncpg æ ¼å¼ï¼‰
                    # å­—å…¸çš„é”®é¡ºåºä¸é‡è¦ï¼Œä½†å€¼çš„é¡ºåºå¿…é¡»åŒ¹é… SQL ä¸­çš„å ä½ç¬¦é¡ºåº
                    sql = """
                        UPDATE LIGHTRAG_DOC_FULL 
                        SET meta = $1::jsonb
                        WHERE id = $2 AND workspace = $3
                    """
                    try:
                        # æŒ‰ SQL å ä½ç¬¦é¡ºåºä¼ é€’å€¼ï¼š$1=metadata_json, $2=doc_id, $3=workspace
                        # æ³¨æ„ï¼šå­—å…¸çš„å€¼çš„é¡ºåºå¿…é¡»ä¸ SQL å ä½ç¬¦é¡ºåºä¸€è‡´
                        await db.execute(sql, {
                            'meta_json': metadata_json,  # $1
                            'doc_id': doc_id,            # $2
                            'workspace': workspace       # $3
                        })
                        updated_count += 1
                    except Exception as e:
                        logger.warning(f"æ›´æ–° Metadata å¤±è´¥ (doc_id={doc_id}): {e}")
                        continue
                
                await ClientManager.release_client(db)
                return updated_count
            
            # è¿è¡Œå¼‚æ­¥æ›´æ–°
            if _is_jupyter() and _jupyter_nest_asyncio_enabled:
                # Jupyter ç¯å¢ƒï¼Œç›´æ¥è¿è¡Œ
                import nest_asyncio
                return nest_asyncio.run(update_metadata_async())
            else:
                # æ™®é€šç¯å¢ƒï¼Œä½¿ç”¨ asyncio.run
                return asyncio.run(update_metadata_async())
                
        except Exception as e:
            logger.error(f"æ‰¹é‡æ›´æ–° Metadata å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return 0
    
    def ingest_from_file(self, file_path: str) -> Dict[str, Any]:
        """
        ä»æ–‡ä»¶å¯¼å…¥ï¼ˆå¼€å‘é˜¶æ®µä½¿ç”¨ï¼‰
        
        Args:
            file_path: Clean Artifact æ–‡ä»¶è·¯å¾„
            
        Returns:
            å¯¼å…¥ç»“æœç»Ÿè®¡ä¿¡æ¯
        """
        batch = CleanBatch.load_from_file(file_path)
        return self.ingest_batch(batch)
    
    def ingest_from_json_file(self, json_file_path: str) -> Dict[str, Any]:
        """
        ä» GitHubIngestor è¾“å‡ºçš„ JSON æ–‡ä»¶å¯¼å…¥æ–‡æ¡£åˆ° LightRAG
        
        Args:
            json_file_path: JSON æ–‡ä»¶è·¯å¾„
            
        Returns:
            å¯¼å…¥ç»“æœç»Ÿè®¡ä¿¡æ¯
        """
        try:
            json_path = Path(json_file_path)
            if not json_path.exists():
                raise FileNotFoundError(f"JSON æ–‡ä»¶ä¸å­˜åœ¨: {json_file_path}")
            
            # è¯»å– JSON æ–‡ä»¶
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # éªŒè¯æ•°æ®ç»“æ„
            if 'documents' not in data:
                raise ValueError("JSON æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼šç¼ºå°‘ 'documents' å­—æ®µ")
            
            documents = data['documents']
            if not isinstance(documents, list):
                raise ValueError("JSON æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼š'documents' å¿…é¡»æ˜¯åˆ—è¡¨")
            
            # æå–æ–‡æœ¬å†…å®¹å’Œæ–‡ä»¶è·¯å¾„
            texts = []
            file_paths = []
            
            for doc in documents:
                if 'content' not in doc:
                    logger.warning(f"æ–‡æ¡£ç¼ºå°‘ 'content' å­—æ®µï¼Œè·³è¿‡: {doc.get('path', 'unknown')}")
                    continue
                
                texts.append(doc['content'])
                
                # ä¼˜å…ˆä½¿ç”¨ path å­—æ®µï¼Œå…¶æ¬¡ä½¿ç”¨ metadata.path
                file_path = doc.get('path') or doc.get('metadata', {}).get('path', '')
                file_paths.append(file_path)
            
            if not texts:
                logger.warning("æ²¡æœ‰æœ‰æ•ˆçš„æ–‡æ¡£å†…å®¹")
                return {
                    'success': False,
                    'message': 'æ²¡æœ‰æœ‰æ•ˆçš„æ–‡æ¡£å†…å®¹',
                    'total_documents': 0
                }
            
            # è°ƒç”¨ LightRAG çš„ insert æ–¹æ³•
            try:
                self.rag.insert(texts, file_paths=file_paths)
            except RuntimeError as e:
                # å¦‚æœæ˜¯äº‹ä»¶å¾ªç¯é”™è¯¯ï¼Œå°è¯•ä½¿ç”¨å¼‚æ­¥æ–¹æ³•
                error_msg = str(e).lower()
                if "event loop" in error_msg or "already running" in error_msg:
                    if _is_jupyter():
                        logger.warning("âš ï¸ æ£€æµ‹åˆ° Jupyter äº‹ä»¶å¾ªç¯å†²çªï¼Œå°è¯•ä½¿ç”¨å¼‚æ­¥æ–¹æ³•...")
                        logger.info("ğŸ’¡ æç¤º: å®‰è£… nest-asyncio å¯é¿å…æ­¤é—®é¢˜: pip install nest-asyncio")
                        try:
                            # åœ¨ Jupyter ä¸­ï¼Œå°è¯•ä½¿ç”¨ nest_asyncio æˆ–ç›´æ¥ä½¿ç”¨å¼‚æ­¥æ–¹æ³•
                            if _jupyter_nest_asyncio_enabled:
                                # nest_asyncio å·²å¯ç”¨ï¼Œé‡è¯• insert
                                self.rag.insert(texts, file_paths=file_paths)
                            else:
                                # å°è¯•åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œ
                                import concurrent.futures
                                with concurrent.futures.ThreadPoolExecutor() as executor:
                                    future = executor.submit(
                                        lambda: asyncio.run(self.rag.ainsert(texts, file_paths=file_paths))
                                    )
                                    future.result()
                        except Exception as e2:
                            error_detail = str(e2)
                            logger.error(f"âŒ å¼‚æ­¥æ–¹æ³•ä¹Ÿå¤±è´¥: {error_detail}")
                            if "event loop" in error_detail.lower():
                                raise RuntimeError(
                                    "äº‹ä»¶å¾ªç¯å†²çªã€‚è¯·åœ¨ Jupyter Notebook çš„ç¬¬ä¸€ä¸ª cell ä¸­è¿è¡Œ:\n"
                                    "  !pip install nest-asyncio\n"
                                    "  import nest_asyncio\n"
                                    "  nest_asyncio.apply()"
                                ) from e2
                            raise RuntimeError(f"å¯¼å…¥æ–‡æ¡£æ—¶å‘ç”Ÿé”™è¯¯: {error_detail}") from e2
                    else:
                        raise RuntimeError(f"äº‹ä»¶å¾ªç¯é”™è¯¯: {e}") from e
                else:
                    raise
            
            # ç»Ÿè®¡ä¿¡æ¯
            result = {
                'success': True,
                'total_documents': len(texts),
                'source': data.get('source', 'unknown'),
                'repo_url': data.get('repo_url', ''),
                'extracted_at': data.get('extracted_at', ''),
                'type_distribution': data.get('type_distribution', {})
            }
            
            logger.info(f"æˆåŠŸå¯¼å…¥ {len(texts)} ä¸ªæ–‡æ¡£åˆ° LightRAG")
            logger.info(f"æ•°æ®æº: {result['source']}, ä»“åº“: {result['repo_url']}")
            
            return result
            
        except FileNotFoundError as e:
            logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {e}")
            raise
        except json.JSONDecodeError as e:
            logger.error(f"JSON è§£æå¤±è´¥: {e}")
            raise ValueError(f"JSON æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")
        except RuntimeError as e:
            # äº‹ä»¶å¾ªç¯é”™è¯¯å·²åœ¨ä¸Šé¢å¤„ç†ï¼Œè¿™é‡Œåªå¤„ç†å…¶ä»– RuntimeError
            error_msg = str(e)
            if "event loop" not in error_msg.lower() and "already running" not in error_msg.lower():
                logger.error(f"âŒ å¯¼å…¥æ–‡æ¡£å¤±è´¥: {error_msg}")
            raise
        except Exception as e:
            error_msg = str(e)
            logger.error(f"âŒ å¯¼å…¥æ–‡æ¡£å¤±è´¥: {error_msg}")
            # æä¾›æ›´å‹å¥½çš„é”™è¯¯ä¿¡æ¯
            if "api" in error_msg.lower() or "key" in error_msg.lower():
                logger.error("ğŸ’¡ æç¤º: è¯·æ£€æŸ¥ API é…ç½®å’Œå¯†é’¥æ˜¯å¦æ­£ç¡®è®¾ç½®")
            elif "model" in error_msg.lower() or "llm" in error_msg.lower() or "none" in error_msg.lower():
                logger.error("ğŸ’¡ æç¤º: è¯·æ£€æŸ¥æ¨¡å‹é…ç½®æ˜¯å¦æ­£ç¡®ï¼Œç¡®ä¿ API å¯†é’¥å·²è®¾ç½®ä¸”æ¨¡å‹å¯ç”¨")
                logger.error("ğŸ’¡ æç¤º: æ£€æŸ¥ DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡æˆ– config.yaml ä¸­çš„ models.api.api_key")
            raise
    
    def query(
        self,
        query: str,
        mode: str = "hybrid",  # "global", "local", "hybrid"
        top_k: int = 5
    ) -> Dict[str, Any]:
        """
        æŸ¥è¯¢çŸ¥è¯†åº“
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            mode: æ£€ç´¢æ¨¡å¼ï¼ˆglobal/local/hybridï¼‰
            top_k: è¿”å›çš„ top-k ç»“æœæ•°
            
        Returns:
            æŸ¥è¯¢ç»“æœå­—å…¸ï¼ŒåŒ…å« answer, contexts, entities ç­‰
        """
        try:
            # TODO: æ ¹æ®å®é™… LightRAG API è°ƒæ•´æŸ¥è¯¢å‚æ•°
            query_param = QueryParam(
                query=query,
                mode=mode,
                top_k=top_k
            )
            
            result = self.rag.query(query_param)
            
            # æ ¼å¼åŒ–è¿”å›ç»“æœ
            return {
                'answer': result.get('answer', ''),
                'contexts': result.get('contexts', []),
                'entities': result.get('entities', []),
                'relations': result.get('relations', []),
                'context_ids': result.get('context_ids', [])
            }
        except Exception as e:
            logger.error(f"æŸ¥è¯¢å¤±è´¥: {e}")
            raise
    
    def get_entity_context(self, entity_name: str) -> List[Dict[str, Any]]:
        """
        è·å–å®ä½“çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
        
        Args:
            entity_name: å®ä½“åç§°
            
        Returns:
            å®ä½“ä¸Šä¸‹æ–‡åˆ—è¡¨
        """
        try:
            # TODO: æ ¹æ®å®é™… LightRAG API è°ƒæ•´
            return self.rag.get_entity_context(entity_name)
        except Exception as e:
            logger.error(f"è·å–å®ä½“ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            return []

