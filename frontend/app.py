"""
Streamlit å‰ç«¯åº”ç”¨
"""
import streamlit as st
import requests
import time
from typing import Optional

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="GRAG æŠ€æœ¯æ–‡æ¡£æ™ºèƒ½é—®ç­”ç³»ç»Ÿ",
    page_icon="ğŸ¤–",
    layout="wide"
)

# API é…ç½®
API_BASE_URL = "http://localhost:8000/api/v1"
API_USERNAME = st.secrets.get("API_USERNAME", "admin")
API_PASSWORD = st.secrets.get("API_PASSWORD", "")

# ä¼šè¯çŠ¶æ€åˆå§‹åŒ–
if "messages" not in st.session_state:
    st.session_state.messages = []
if "current_model" not in st.session_state:
    st.session_state.current_model = "unknown"


def get_auth_headers():
    """è·å–è®¤è¯å¤´"""
    import base64
    credentials = f"{API_USERNAME}:{API_PASSWORD}"
    encoded = base64.b64encode(credentials.encode()).decode()
    return {"Authorization": f"Basic {encoded}"}


def query_api(query: str, stream: bool = False) -> Optional[dict]:
    """
    è°ƒç”¨ API è¿›è¡ŒæŸ¥è¯¢
    
    Args:
        query: æŸ¥è¯¢æ–‡æœ¬
        stream: æ˜¯å¦æµå¼è¿”å›
        
    Returns:
        æŸ¥è¯¢ç»“æœå­—å…¸
    """
    try:
        url = f"{API_BASE_URL}/query/stream" if stream else f"{API_BASE_URL}/query"
        
        response = requests.post(
            url,
            json={"query": query, "use_cache": True, "stream": stream},
            headers=get_auth_headers(),
            stream=stream,
            timeout=60
        )
        response.raise_for_status()
        
        if stream:
            return {"stream": True, "response": response}
        else:
            return response.json()
    except Exception as e:
        st.error(f"API è°ƒç”¨å¤±è´¥: {e}")
        return None


def submit_feedback(query: str, is_positive: bool):
    """
    æäº¤ç”¨æˆ·åé¦ˆ
    
    Args:
        query: æŸ¥è¯¢æ–‡æœ¬
        is_positive: æ˜¯å¦ä¸ºæ­£é¢åé¦ˆ
    """
    try:
        response = requests.post(
            f"{API_BASE_URL}/feedback",
            json={"query": query, "is_positive": is_positive},
            headers=get_auth_headers(),
            timeout=10
        )
        response.raise_for_status()
        return response.json()
    except Exception as e:
        st.error(f"åé¦ˆæäº¤å¤±è´¥: {e}")
        return None


def get_stats():
    """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
    try:
        response = requests.get(
            f"{API_BASE_URL}/stats",
            headers=get_auth_headers(),
            timeout=10
        )
        response.raise_for_status()
        return response.json()
    except Exception as e:
        st.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
        return None


def switch_model(model_type: str) -> bool:
    """
    åˆ‡æ¢æ¨¡å‹
    
    Args:
        model_type: æ¨¡å‹ç±»å‹ï¼ˆ"api" æˆ– "local"ï¼Œlocal æš‚æ—¶ç¦ç”¨ï¼‰
        
    Returns:
        æ˜¯å¦åˆ‡æ¢æˆåŠŸ
    """
    try:
        response = requests.post(
            f"{API_BASE_URL}/model/switch",
            json={"model_type": model_type},
            headers=get_auth_headers(),
            timeout=10
        )
        response.raise_for_status()
        result = response.json()
        if result.get("success"):
            st.session_state.current_model = result.get("current_model", "unknown")
        return result.get("success", False)
    except Exception as e:
        st.error(f"æ¨¡å‹åˆ‡æ¢å¤±è´¥: {e}")
        return False


# ä¸»ç•Œé¢
st.title("ğŸ¤– GRAG æŠ€æœ¯æ–‡æ¡£æ™ºèƒ½é—®ç­”ç³»ç»Ÿ")

# ä¾§è¾¹æ 
with st.sidebar:
    st.header("âš™ï¸ ç³»ç»Ÿè®¾ç½®")
    
    # æ¨¡å‹åˆ‡æ¢
    st.subheader("æ¨¡å‹é€‰æ‹©")
    # ========================================================================
    # Ollama æœ¬åœ°æ¨¡å‹æ”¯æŒå·²å¼ƒç”¨
    # ========================================================================
    # model_type = st.selectbox(
    #     "å½“å‰æ¨¡å‹",
    #     ["local", "deepseek"],
    #     index=0 if st.session_state.current_model == "local" else 1
    # )
    
    model_type = st.selectbox(
        "å½“å‰æ¨¡å‹",
        ["api"],  # local æš‚æ—¶ç¦ç”¨
        index=0
    )
    
    if st.button("åˆ‡æ¢æ¨¡å‹"):
        if switch_model(model_type):
            st.success(f"å·²åˆ‡æ¢åˆ° {model_type}")
        else:
            st.error("æ¨¡å‹åˆ‡æ¢å¤±è´¥")
    
    st.divider()
    
    # ç³»ç»Ÿç»Ÿè®¡
    st.subheader("ğŸ“Š ç³»ç»Ÿç»Ÿè®¡")
    if st.button("åˆ·æ–°ç»Ÿè®¡"):
        stats = get_stats()
        if stats:
            metrics = stats.get("metrics", {})
            cache = stats.get("cache", {})
            
            st.metric("API è°ƒç”¨æ¬¡æ•°", sum(metrics.get("api_calls", {}).values()))
            st.metric("ç¼“å­˜æ¡ç›®æ•°", cache.get("total_entries", 0))
            st.metric("å¹³å‡è´¨é‡è¯„åˆ†", f"{cache.get('average_quality_score', 0):.2f}")
    
    st.divider()
    
    # æ¸…ç©ºå¯¹è¯
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯å†å²"):
        st.session_state.messages = []
        st.rerun()

# ä¸»èŠå¤©ç•Œé¢
# æ˜¾ç¤ºå†å²æ¶ˆæ¯
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if message.get("query") and message.get("answer"):
            # åé¦ˆæŒ‰é’®
            col1, col2 = st.columns(2)
            with col1:
                if st.button("ğŸ‘", key=f"positive_{message['id']}"):
                    submit_feedback(message["query"], True)
                    st.success("æ„Ÿè°¢æ‚¨çš„åé¦ˆï¼")
            with col2:
                if st.button("ğŸ‘", key=f"negative_{message['id']}"):
                    submit_feedback(message["query"], False)
                    st.info("æ„Ÿè°¢æ‚¨çš„åé¦ˆï¼Œæˆ‘ä»¬ä¼šæ”¹è¿›ï¼")

# ç”¨æˆ·è¾“å…¥
if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    st.session_state.messages.append({
        "role": "user",
        "content": prompt,
        "id": len(st.session_state.messages)
    })
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # æ˜¾ç¤ºåŠ©æ‰‹å›å¤
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        # è°ƒç”¨ API
        result = query_api(prompt, stream=False)
        
        if result and result.get("success"):
            answer = result.get("answer", "")
            full_response = answer
            message_placeholder.markdown(full_response)
            
            # æ˜¾ç¤ºé¢å¤–ä¿¡æ¯
            with st.expander("ğŸ“‹ è¯¦ç»†ä¿¡æ¯"):
                st.write(f"**å“åº”æ—¶é—´**: {result.get('response_time', 0):.2f} ç§’")
                st.write(f"**æ¨¡å‹ç±»å‹**: {result.get('model_type', 'unknown')}")
                st.write(f"**æ¥è‡ªç¼“å­˜**: {'æ˜¯' if result.get('from_cache') else 'å¦'}")
                if result.get("context_ids"):
                    st.write(f"**ä¸Šä¸‹æ–‡æ•°é‡**: {len(result.get('context_ids', []))}")
        else:
            error_msg = result.get("error", "æŸ¥è¯¢å¤±è´¥") if result else "API è°ƒç”¨å¤±è´¥"
            message_placeholder.error(f"âŒ {error_msg}")
            full_response = f"é”™è¯¯: {error_msg}"
        
        # æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯
        st.session_state.messages.append({
            "role": "assistant",
            "content": full_response,
            "query": prompt,
            "answer": full_response,
            "id": len(st.session_state.messages)
        })

