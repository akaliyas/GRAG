"""
Pipeline Step 1: Fetchï¼ˆæå–åŸå§‹æ•°æ®ï¼‰
ä» GitHub ä»“åº“æå–æ–‡æ¡£ï¼Œä¿å­˜ä¸º Raw Artifactï¼ˆartifacts/01_raw/ï¼‰

ä½¿ç”¨æ–¹å¼ï¼š
    uv run scripts/pipeline_fetch.py --repo https://github.com/openai/openai-python --output artifacts/01_raw/openai_v1_raw.json
"""
import argparse
import logging
import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


def check_uv_environment():
    """æ£€æŸ¥æ˜¯å¦åœ¨ uv ç¯å¢ƒä¸­è¿è¡Œ"""
    # æ£€æŸ¥ç¯å¢ƒå˜é‡ï¼ˆæŸäº›æƒ…å†µä¸‹ uv ä¼šè®¾ç½®æ­¤å˜é‡ï¼‰
    if os.getenv('UV_PROJECT_ENVIRONMENT'):
        return True
    
    # æ£€æŸ¥æ˜¯å¦åœ¨é¡¹ç›®è™šæ‹Ÿç¯å¢ƒä¸­ï¼ˆ.venv ç›®å½•å­˜åœ¨ï¼‰
    project_root = Path(__file__).parent.parent
    venv_path = project_root / '.venv'
    if venv_path.exists() and sys.prefix and str(venv_path) in sys.prefix:
        return True
    
    # æ£€æŸ¥æ˜¯å¦é€šè¿‡ uv run å¯åŠ¨ï¼ˆæ£€æŸ¥ sys.executable è·¯å¾„ï¼‰
    if sys.executable:
        executable_path = Path(sys.executable)
        # å¦‚æœåœ¨ .venv ç›®å½•ä¸­ï¼Œè¯´æ˜å¯èƒ½æ˜¯é€šè¿‡ uv ç®¡ç†çš„
        if '.venv' in str(executable_path):
            return True
    
    # å¦‚æœé¡¹ç›®æ ¹ç›®å½•æœ‰ .venvï¼Œå‡è®¾ä½¿ç”¨ uv ç®¡ç†
    if venv_path.exists():
        return True
    
    return False


def ensure_uv_environment():
    """ç¡®ä¿åœ¨ uv ç¯å¢ƒä¸­è¿è¡Œï¼Œå¦åˆ™æç¤ºç”¨æˆ·"""
    if not check_uv_environment():
        logger = logging.getLogger(__name__)
        logger.warning("âš ï¸  å»ºè®®ä½¿ç”¨ 'uv run' æ¥æ‰§è¡Œæ­¤è„šæœ¬")
        logger.warning("   ç¤ºä¾‹: uv run scripts/pipeline_fetch.py --repo <repo-url>")
        logger.warning("   å½“å‰å°†ç»§ç»­æ‰§è¡Œï¼Œä½†å¯èƒ½ç¼ºå°‘ä¾èµ–...")
        logger.warning("")

from agent.tools.github_ingestor import GitHubIngestor
from utils.schema import IngestionBatch

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def main():
    # æ£€æŸ¥ uv ç¯å¢ƒ
    ensure_uv_environment()
    
    parser = argparse.ArgumentParser(description='ä» GitHub ä»“åº“æå–æ–‡æ¡£ï¼ˆStep 1: Fetchï¼‰')
    parser.add_argument(
        '--repo',
        type=str,
        required=True,
        help='GitHub ä»“åº“ URLï¼ˆå¦‚ https://github.com/openai/openai-pythonï¼‰'
    )
    parser.add_argument(
        '--output',
        type=str,
        required=True,
        help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆRaw Artifactï¼Œå¦‚ artifacts/01_raw/openai_v1_raw.jsonï¼‰'
    )
    parser.add_argument(
        '--extensions',
        type=str,
        nargs='+',
        default=['.md', '.mdx', '.ipynb'],
        help='æ–‡ä»¶æ‰©å±•ååˆ—è¡¨ï¼ˆé»˜è®¤: .md .mdx .ipynbï¼‰'
    )
    parser.add_argument(
        '--max-files',
        type=int,
        default=None,
        help='æœ€å¤§æ–‡ä»¶æ•°ï¼ˆå¯é€‰ï¼Œé»˜è®¤æ— é™åˆ¶ï¼‰'
    )
    parser.add_argument(
        '--include-paths',
        type=str,
        nargs='+',
        default=None,
        help='åŒ…å«çš„è·¯å¾„å‰ç¼€åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰'
    )
    parser.add_argument(
        '--exclude-paths',
        type=str,
        nargs='+',
        default=None,
        help='æ’é™¤çš„è·¯å¾„å‰ç¼€åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰'
    )
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ– GitHubIngestor
    logger.info("åˆå§‹åŒ– GitHubIngestor...")
    try:
        ingestor = GitHubIngestor()
    except Exception as e:
        logger.error(f"åˆå§‹åŒ–å¤±è´¥: {e}")
        sys.exit(1)
    
    # æå–æ–‡æ¡£
    logger.info(f"å¼€å§‹æå–æ–‡æ¡£: {args.repo}")
    logger.info(f"æ–‡ä»¶æ‰©å±•å: {args.extensions}")
    if args.max_files:
        logger.info(f"æœ€å¤§æ–‡ä»¶æ•°: {args.max_files}")
    if args.include_paths:
        logger.info(f"åŒ…å«è·¯å¾„: {args.include_paths}")
    if args.exclude_paths:
        logger.info(f"æ’é™¤è·¯å¾„: {args.exclude_paths}")
    
    try:
        batch = ingestor.extract_repo_docs(
            repo_url=args.repo,
            file_extensions=args.extensions,
            max_files=args.max_files,
            include_paths=args.include_paths,
            exclude_paths=args.exclude_paths
        )
        
        logger.info(f"âœ… æˆåŠŸæå– {len(batch.docs)} ä¸ªæ–‡æ¡£")
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        output_path = Path(args.output)
        batch.save_to_file(str(output_path))
        
        logger.info(f"âœ… å·²ä¿å­˜åˆ°: {output_path}")
        logger.info(f"   æ–‡ä»¶å¤§å°: {output_path.stat().st_size / 1024:.2f} KB")
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        type_counts = {}
        total_chars = 0
        for doc in batch.docs:
            doc_type = doc.metadata.get('type', 'unknown')
            type_counts[doc_type] = type_counts.get(doc_type, 0) + 1
            total_chars += len(doc.content)
        
        logger.info("\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        logger.info(f"  æ€»æ–‡æ¡£æ•°: {len(batch.docs)}")
        logger.info(f"  æ€»å­—ç¬¦æ•°: {total_chars:,}")
        logger.info(f"  æ–‡ä»¶ç±»å‹åˆ†å¸ƒ:")
        for doc_type, count in type_counts.items():
            logger.info(f"    - {doc_type}: {count} ä¸ª")
        
        logger.info("\nâœ… Step 1 (Fetch) å®Œæˆï¼")
        logger.info(f"ä¸‹ä¸€æ­¥: è¿è¡Œ pipeline_clean.py æ¸…æ´—æ•°æ®")
        logger.info(f"  uv run scripts/pipeline_clean.py --input {output_path}")
        
    except Exception as e:
        logger.error(f"âŒ æå–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()

